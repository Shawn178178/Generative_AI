# HW4 - LLM Application and Fine-Tuning

This project consists of two tasks involving Large Language Models (LLMs):

1. **LLM as a Research Assistant**  
   Used ChatGPT to retrieve recent papers via prompting.

2. **Fine-Tuning a Language Model**  
   Trained a model on a customer churn dataset using Colab, Hugging Face, and Ollama.

## ðŸ”— Key Resources

- ðŸ“„ **ChatGPT Share**:  
  [https://chatgpt.com/share/677e7cfd-ac14-800d-8f86-72c7f7a77338](https://chatgpt.com/share/677e7cfd-ac14-800d-8f86-72c7f7a77338)

- ðŸ“Š **Dataset (Kaggle)**:  
  [Telco Customer Churn](https://www.kaggle.com/datasets/palashfendarkar/wa-fnusec-telcocustomerchurn/data)

- ðŸ’» **Colab Notebook**:  
  [https://colab.research.google.com/drive/1SUFgHhwx6pdwGGJawFbORflBfLZwIQ-h?usp=sharing](https://colab.research.google.com/drive/1SUFgHhwx6pdwGGJawFbORflBfLZwIQ-h?usp=sharing)

- ðŸ“¦ **Hugging Face Model File**:  
  [Modelfile on Hugging Face](https://huggingface.co/Osamu1013/churn_model/resolve/main/Modelfile)

## ðŸ§¾ Author

**Student ID**: n96131281  
**Institution**: NCKUES  
**Course**: Generative Artificial Intelligence
